we can use the 'sort' and 'uniq' commands in linux to get the duplicate word count in a file, and then redirect the output to a new file.

sort <filename> | uniq -c | grep -v "^\s*1\s*" > output_file.txt

(main.bash: line 7: syntax error near unexpected token `|'
main.bash: line 7: `sort <filename> | uniq -c | grep -v "^\s*1\s*" > output_file.txt'


...Program finished with exit code 2
Press ENTER to exit console.)

This command will sort the contents of 'filename' and then pass them to the 'uniq' command, which will removeall duplicates except for the onces that appear more than once.The output of 'uniq -d' will then be redirect to 'output_filename'.

If we also want to see the actual duplicate words that were counted, we can remove the '-d' option from the 'uniq' command, like this:

sort filename | uniq > output_filename

(sort: cannot read: filename: No such file or directory


...Program finished with exit code 0
Press ENTER to exit console.)

This will output a list of all unique words in the file, along with their frequency.



